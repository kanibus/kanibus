{
  "version": "0.4",
  "last_node_id": 15,
  "last_link_id": 35,
  "nodes": [
    {
      "id": 1,
      "type": "VideoFrameLoader",
      "pos": [50, 50],
      "size": {"0": 315, "1": 400},
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {"name": "frames", "type": "IMAGE", "links": [1, 2, 3, 4], "shape": 3},
        {"name": "metadata", "type": "VIDEO_METADATA", "links": [5], "shape": 3},
        {"name": "total_frames", "type": "INT", "links": [6], "shape": 3},
        {"name": "actual_fps", "type": "FLOAT", "links": [7], "shape": 3}
      ],
      "properties": {"Node name for S&R": "VideoFrameLoader"},
      "widgets_values": [
        "input_video.mp4",
        0,
        -1,
        1,
        30.0,
        1280,
        720,
        "high",
        true,
        8,
        64,
        4.0,
        "RGB"
      ],
      "color": "#432",
      "bgcolor": "#653",
      "title": "üìπ Advanced Video Loader (Adaptive Resolution)"
    },
    {
      "id": 2,
      "type": "KanibusMaster",
      "pos": [400, 50],
      "size": {"0": 450, "1": 700},
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [
        {"name": "image", "type": "IMAGE", "link": 1},
        {"name": "video_metadata", "type": "VIDEO_METADATA", "link": 5}
      ],
      "outputs": [
        {"name": "kanibus_result", "type": "KANIBUS_RESULT", "links": [8], "shape": 3},
        {"name": "processed_image", "type": "IMAGE", "links": [9], "shape": 3},
        {"name": "eye_mask", "type": "MASK", "links": [10, 11], "shape": 3},
        {"name": "depth_map", "type": "IMAGE", "links": [12, 13], "shape": 3},
        {"name": "normal_map", "type": "IMAGE", "links": [14, 15], "shape": 3},
        {"name": "pose_visualization", "type": "IMAGE", "links": [16], "shape": 3},
        {"name": "controlnet_conditioning", "type": "CONDITIONING", "links": [17, 18], "shape": 3},
        {"name": "processing_report", "type": "STRING", "links": [19], "shape": 3}
      ],
      "properties": {"Node name for S&R": "KanibusMaster"},
      "widgets_values": [
        "video",
        "streaming",
        "auto_detect",
        30.0,
        true,
        true,
        true,
        true,
        true,
        true,
        true,
        "ultra",
        "high",
        0.8,
        1.3,
        1.0,
        0.7,
        0.9,
        0.6,
        0.5,
        8,
        true,
        true
      ],
      "color": "#234",
      "bgcolor": "#567",
      "title": "üß† Kanibus Master (Integrated Pipeline)"
    },
    {
      "id": 3,
      "type": "NeuralPupilTracker",
      "pos": [900, 50],
      "size": {"0": 315, "1": 400},
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [
        {"name": "image", "type": "IMAGE", "link": 2}
      ],
      "outputs": [
        {"name": "tracking_result", "type": "EYE_TRACKING_RESULT", "links": [20], "shape": 3},
        {"name": "annotated_image", "type": "IMAGE", "links": [21], "shape": 3},
        {"name": "gaze_visualization", "type": "IMAGE", "links": [22], "shape": 3},
        {"name": "left_eye_mask", "type": "MASK", "links": [23], "shape": 3},
        {"name": "right_eye_mask", "type": "MASK", "links": [24], "shape": 3}
      ],
      "properties": {"Node name for S&R": "NeuralPupilTracker"},
      "widgets_values": [
        1.2,
        0.6,
        0.25,
        350.0,
        true,
        true,
        true,
        true
      ],
      "color": "#432",
      "bgcolor": "#653",
      "title": "üëÅÔ∏è High-Precision Eye Tracker"
    },
    {
      "id": 4,
      "type": "LandmarkPro468",
      "pos": [1250, 50],
      "size": {"0": 315, "1": 334},
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [
        {"name": "image", "type": "IMAGE", "link": 3}
      ],
      "outputs": [
        {"name": "landmarks", "type": "LANDMARKS_468", "links": [25], "shape": 3},
        {"name": "annotated_image", "type": "IMAGE", "links": [26], "shape": 3},
        {"name": "face_mask", "type": "MASK", "links": [27], "shape": 3},
        {"name": "confidence", "type": "FLOAT", "links": [28], "shape": 3}
      ],
      "properties": {"Node name for S&R": "LandmarkPro468"},
      "widgets_values": [
        0.7,
        0.7,
        true,
        false,
        0.5
      ],
      "color": "#432",
      "bgcolor": "#653",
      "title": "üìç 468-Point Landmarks"
    },
    {
      "id": 5,
      "type": "EmotionAnalyzer",
      "pos": [1600, 50],
      "size": {"0": 315, "1": 334},
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {"name": "image", "type": "IMAGE", "link": 4},
        {"name": "face_landmarks", "type": "LANDMARKS_468", "link": 25}
      ],
      "outputs": [
        {"name": "emotion_scores", "type": "EMOTION_SCORES", "links": [29], "shape": 3},
        {"name": "emotion_visualization", "type": "IMAGE", "links": [30], "shape": 3},
        {"name": "dominant_emotion", "type": "STRING", "links": [31], "shape": 3},
        {"name": "confidence", "type": "FLOAT", "links": [32], "shape": 3}
      ],
      "properties": {"Node name for S&R": "EmotionAnalyzer"},
      "widgets_values": [
        1.0,
        false,
        0.3
      ],
      "color": "#432",
      "bgcolor": "#653",
      "title": "üòä Emotion Analysis"
    },
    {
      "id": 6,
      "type": "TemporalSmoother",
      "pos": [50, 500],
      "size": {"0": 315, "1": 334},
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {"name": "current_frame", "type": "IMAGE", "link": 9}
      ],
      "outputs": [
        {"name": "smoothed_frame", "type": "IMAGE", "links": [33], "shape": 3},
        {"name": "motion_visualization", "type": "IMAGE", "links": null},
        {"name": "motion_amount", "type": "FLOAT", "links": null},
        {"name": "smoothing_applied", "type": "FLOAT", "links": null}
      ],
      "properties": {"Node name for S&R": "TemporalSmoother"},
      "widgets_values": [
        0.8,
        7,
        "exponential",
        true,
        true,
        true
      ],
      "color": "#432",
      "bgcolor": "#653",
      "title": "üîÑ Temporal Consistency"
    },
    {
      "id": 7,
      "type": "MultiControlNetApply",
      "pos": [400, 800],
      "size": {"0": 500, "1": 600},
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {"name": "model", "type": "MODEL", "link": null},
        {"name": "positive", "type": "CONDITIONING", "link": 17},
        {"name": "negative", "type": "CONDITIONING", "link": 18},
        {"name": "eye_mask", "type": "MASK", "link": 10},
        {"name": "depth_map", "type": "IMAGE", "link": 12},
        {"name": "normal_map", "type": "IMAGE", "link": 14}
      ],
      "outputs": [
        {"name": "positive", "type": "CONDITIONING", "links": [34], "shape": 3},
        {"name": "negative", "type": "CONDITIONING", "links": [35], "shape": 3}
      ],
      "properties": {"Node name for S&R": "MultiControlNetApply"},
      "widgets_values": [
        1.3,
        1.0,
        0.7,
        0.9,
        0.6,
        0.5,
        0.4,
        "wan_2.2",
        0.0,
        1.0,
        7.5,
        0.6
      ],
      "color": "#234",
      "bgcolor": "#567",
      "title": "üéõÔ∏è Integrated ControlNet (WAN 2.1/2.2)"
    },
    {
      "id": 8,
      "type": "PreviewImage",
      "pos": [950, 500],
      "size": {"0": 315, "1": 246},
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {"name": "images", "type": "IMAGE", "link": 33}
      ],
      "properties": {"Node name for S&R": "PreviewImage"},
      "title": "üñºÔ∏è Final Output Preview"
    },
    {
      "id": 9,
      "type": "PreviewImage",
      "pos": [1300, 500],
      "size": {"0": 315, "1": 246},
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {"name": "images", "type": "IMAGE", "link": 21}
      ],
      "properties": {"Node name for S&R": "PreviewImage"},
      "title": "üëÅÔ∏è Eye Tracking Visualization"
    },
    {
      "id": 10,
      "type": "PreviewImage",
      "pos": [1650, 500],
      "size": {"0": 315, "1": 246},
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {"name": "images", "type": "IMAGE", "link": 30}
      ],
      "properties": {"Node name for S&R": "PreviewImage"},
      "title": "üòä Emotion Visualization"
    },
    {
      "id": 11,
      "type": "SaveImage",
      "pos": [400, 1500],
      "size": {"0": 315, "1": 270},
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {"name": "images", "type": "IMAGE", "link": 33}
      ],
      "properties": {"Node name for S&R": "SaveImage"},
      "widgets_values": ["kanibus_advanced_output"],
      "title": "üíæ Save Final Result"
    },
    {
      "id": 12,
      "type": "Note",
      "pos": [50, 900],
      "size": {"0": 300, "1": 200},
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {"text": "üéØ ADVANCED INTEGRATED WORKFLOW\n\n‚ú® Features:\n‚Ä¢ Dual WAN 2.1/2.2 compatibility\n‚Ä¢ Full 468-point facial landmarks\n‚Ä¢ Advanced eye tracking with 3D gaze\n‚Ä¢ Real-time emotion analysis\n‚Ä¢ Temporal frame consistency\n‚Ä¢ Multi-modal ControlNet integration\n\n‚ö° Performance:\n‚Ä¢ Adaptive resolution (480p-720p)\n‚Ä¢ GPU memory optimization\n‚Ä¢ Intelligent caching system\n‚Ä¢ Real-time processing capability\n\nüéõÔ∏è Controls:\n‚Ä¢ Eye mask control (scribble)\n‚Ä¢ Depth map control\n‚Ä¢ Normal map control\n‚Ä¢ Pose control (optional)\n‚Ä¢ Emotion-aware generation"},
      "color": "#432",
      "bgcolor": "#653",
      "title": "üìã Workflow Documentation"
    },
    {
      "id": 13,
      "type": "Note",
      "pos": [400, 1200],
      "size": {"0": 500, "1": 150},
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {"text": "üîß CONFIGURATION NOTES:\n\n‚Ä¢ VideoFrameLoader: Set to 720p for WAN 2.2 quality, will auto-downscale for WAN 2.1\n‚Ä¢ KanibusMaster: 'auto_detect' mode automatically optimizes for available WAN version\n‚Ä¢ MultiControlNetApply: Integrated weights optimized for both WAN versions\n‚Ä¢ All processing nodes use enhanced parameters for maximum quality\n\n‚ö†Ô∏è GPU Requirements: 8GB+ VRAM recommended for full pipeline"},
      "color": "#234",
      "bgcolor": "#567",
      "title": "‚öôÔ∏è Configuration Guide"
    },
    {
      "id": 14,
      "type": "Note",
      "pos": [950, 800],
      "size": {"0": 400, "1": 200},
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {"text": "üìä MONITORING OUTPUTS:\n\n‚Ä¢ processing_report: Detailed performance metrics\n‚Ä¢ emotion_scores: Real-time emotion analysis data\n‚Ä¢ tracking_result: Complete eye tracking data\n‚Ä¢ confidence scores: Quality metrics for all components\n\nüéØ Use these outputs for:\n‚Ä¢ Performance monitoring\n‚Ä¢ Quality assessment\n‚Ä¢ Debug information\n‚Ä¢ Analytics and research"},
      "color": "#432",
      "bgcolor": "#653",
      "title": "üìà Output Monitoring"
    },
    {
      "id": 15,
      "type": "Note",
      "pos": [1400, 800],
      "size": {"0": 350, "1": 180},
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {"text": "üöÄ PERFORMANCE TIPS:\n\n‚Ä¢ For WAN 2.1: Reduce resolution to 854x480\n‚Ä¢ For WAN 2.2: Use full 1280x720 resolution  \n‚Ä¢ Batch size: Start with 4, increase if GPU allows\n‚Ä¢ Quality: Use 'high' for production, 'medium' for testing\n‚Ä¢ Temporal smoothing: 0.8 for videos, 0.4 for real-time\n\nüí° Monitor GPU memory usage and adjust accordingly"},
      "color": "#234",
      "bgcolor": "#567",
      "title": "‚ö° Performance Optimization"
    }
  ],
  "links": [
    [1, 1, 0, 2, 0, "IMAGE"],
    [2, 1, 0, 3, 0, "IMAGE"],
    [3, 1, 0, 4, 0, "IMAGE"],
    [4, 1, 0, 5, 0, "IMAGE"],
    [5, 1, 1, 2, 1, "VIDEO_METADATA"],
    [6, 1, 2, null, null, "INT"],
    [7, 1, 3, null, null, "FLOAT"],
    [8, 2, 0, null, null, "KANIBUS_RESULT"],
    [9, 2, 1, 6, 0, "IMAGE"],
    [10, 2, 2, 7, 3, "MASK"],
    [11, 2, 2, null, null, "MASK"],
    [12, 2, 3, 7, 4, "IMAGE"],
    [13, 2, 3, null, null, "IMAGE"],
    [14, 2, 4, 7, 5, "IMAGE"],
    [15, 2, 4, null, null, "IMAGE"],
    [16, 2, 5, null, null, "IMAGE"],
    [17, 2, 6, 7, 1, "CONDITIONING"],
    [18, 2, 6, 7, 2, "CONDITIONING"],
    [19, 2, 7, null, null, "STRING"],
    [20, 3, 0, null, null, "EYE_TRACKING_RESULT"],
    [21, 3, 1, 9, 0, "IMAGE"],
    [22, 3, 2, null, null, "IMAGE"],
    [23, 3, 3, null, null, "MASK"],
    [24, 3, 4, null, null, "MASK"],
    [25, 4, 0, 5, 1, "LANDMARKS_468"],
    [26, 4, 1, null, null, "IMAGE"],
    [27, 4, 2, null, null, "MASK"],
    [28, 4, 3, null, null, "FLOAT"],
    [29, 5, 0, null, null, "EMOTION_SCORES"],
    [30, 5, 1, 10, 0, "IMAGE"],
    [31, 5, 2, null, null, "STRING"],
    [32, 5, 3, null, null, "FLOAT"],
    [33, 6, 0, 8, 0, "IMAGE"],
    [33, 6, 0, 11, 0, "IMAGE"],
    [34, 7, 0, null, null, "CONDITIONING"],
    [35, 7, 1, null, null, "CONDITIONING"]
  ],
  "groups": [
    {
      "title": "üé¨ INPUT PROCESSING",
      "bounding": [25, 25, 1925, 450],
      "color": "#3f789e",
      "font_size": 24
    },
    {
      "title": "üîÑ TEMPORAL & CONTROLNET",
      "bounding": [25, 475, 925, 950],
      "color": "#a1309b",
      "font_size": 24
    },
    {
      "title": "üñºÔ∏è OUTPUT & MONITORING",
      "bounding": [950, 475, 1000, 550],
      "color": "#88a15e",
      "font_size": 24
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.7,
      "offset": [-50, -25]
    },
    "info": {
      "name": "Kanibus Advanced Integrated Workflow",
      "author": "Kanibus Team - Claude Flow Hive Mind",
      "description": "Advanced workflow integrating WAN 2.1 and WAN 2.2 compatibility with full multi-modal pipeline including eye tracking, emotion analysis, landmarks, and temporal consistency",
      "version": "1.0",
      "created": "2025-08-04",
      "compatibility": ["WAN 2.1", "WAN 2.2"],
      "features": [
        "Dual WAN compatibility",
        "468-point facial landmarks",
        "3D eye tracking with gaze estimation",
        "Real-time emotion analysis",
        "Temporal frame consistency",
        "Multi-modal ControlNet integration",
        "GPU memory optimization",
        "Adaptive resolution processing"
      ],
      "requirements": {
        "gpu_memory": "8GB+ recommended",
        "resolution": "720p default (adaptive)",
        "models": [
          "control_v11p_sd15_scribble.pth",
          "control_v11f1p_sd15_depth.pth",
          "control_v11p_sd15_normalbae.pth",
          "control_v11p_sd15_openpose.pth"
        ]
      }
    }
  }
}